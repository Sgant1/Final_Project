{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4daef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import dependencies\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from config import db_password\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959a13a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Files to load\n",
    "load_2019_01 = \"cleaned_months_2019/Clean_2019_01.csv\"\n",
    "load_2019_02 = \"cleaned_months_2019/Clean_2019_02.csv\"\n",
    "load_2019_03 = \"cleaned_months_2019/Clean_2019_03.csv\"\n",
    "load_2019_04 = \"cleaned_months_2019/Clean_2019_04.csv\"\n",
    "load_2019_05 = \"cleaned_months_2019/Clean_2019_05.csv\"\n",
    "load_2019_06 = \"cleaned_months_2019/Clean_2019_06.csv\"\n",
    "load_2019_07 = \"cleaned_months_2019/Clean_2019_07.csv\"\n",
    "load_2019_08 = \"cleaned_months_2019/Clean_2019_08.csv\"\n",
    "load_2019_09 = \"cleaned_months_2019/Clean_2019_09.csv\"\n",
    "load_2019_10 = \"cleaned_months_2019/Clean_2019_10.csv\"\n",
    "load_2019_11 = \"cleaned_months_2019/Clean_2019_11.csv\"\n",
    "load_2019_12 = \"cleaned_months_2019/Clean_2019_12.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081d6b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Clean_2019_01.csv into a DataFrame\n",
    "clean_df_2019_01 = pd.read_csv(load_2019_01, index_col=[0])\n",
    "clean_df_2019_01.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9d13b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Clean_2019_02.csv into a DataFrame\n",
    "clean_df_2019_02 = pd.read_csv(load_2019_02, index_col=[0])\n",
    "clean_df_2019_02.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54975db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Clean_2019_03.csv into a DataFrame\n",
    "clean_df_2019_03 = pd.read_csv(load_2019_03, index_col=[0])\n",
    "clean_df_2019_03.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779b2d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Clean_2019_04.csv into a DataFrame\n",
    "clean_df_2019_04 = pd.read_csv(load_2019_04, index_col=[0])\n",
    "clean_df_2019_04.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0735a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Clean_2019_05.csv into a DataFrame\n",
    "clean_df_2019_05 = pd.read_csv(load_2019_05, index_col=[0])\n",
    "clean_df_2019_05.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de9d321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Clean_2019_06.csv into a DataFrame\n",
    "clean_df_2019_06 = pd.read_csv(load_2019_06, index_col=[0])\n",
    "clean_df_2019_06.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e6d1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Clean_2019_07.csv into a DataFrame\n",
    "clean_df_2019_07 = pd.read_csv(load_2019_07, index_col=[0])\n",
    "clean_df_2019_07.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d5a518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Clean_2019_08.csv into a DataFrame\n",
    "clean_df_2019_08 = pd.read_csv(load_2019_08, index_col=[0])\n",
    "clean_df_2019_08.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d643f10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Clean_2019_09.csv into a DataFrame\n",
    "clean_df_2019_09 = pd.read_csv(load_2019_09, index_col=[0])\n",
    "clean_df_2019_09.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7549c23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Clean_2020_10.csv into a DataFrame\n",
    "clean_df_2019_10 = pd.read_csv(load_2019_10, index_col=[0])\n",
    "clean_df_2019_10.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998f9b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Clean_2019_11.csv into a DataFrame\n",
    "clean_df_2019_11 = pd.read_csv(load_2019_11, index_col=[0])\n",
    "clean_df_2019_11.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac5905f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Clean_2020_12.csv into a DataFrame\n",
    "clean_df_2019_12 = pd.read_csv(load_2019_12, index_col=[0])\n",
    "clean_df_2019_12.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f5108b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test appending two df before doing all 12.\n",
    "test_df = clean_df_2019_01.append(clean_df_2019_02, ignore_index = True)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f6720b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count the number of rows in appended df.\n",
    "#clean_df_2019_01: _____ rows\n",
    "#clean_df_2019_02: _____ rows (total row should be _______)\n",
    "test_df.shape[0]\n",
    "#The append worked!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089a330e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Row counts for all 12 df:\n",
    "#clean_df_2019_01: 7,722 rows\n",
    "#clean_df_2019_02: 8,906 rows\n",
    "#clean_df_2019_03: 12,335 rows\n",
    "#clean_df_2019_04: 14,859 rows\n",
    "#clean_df_2019_05: 32,429 rows\n",
    "#clean_df_2019_06: 19,456 rows\n",
    "#clean_df_2019_07: 19,491 rows\n",
    "#clean_df_2019_08: 20,188 rows\n",
    "#clean_df_2019_09: 22,444 rows\n",
    "#clean_df_2019_10: 20,402 rows\n",
    "#clean_df_2019_11: 22,940 rows\n",
    "#clean_df_2019_12: 34,831 rows\n",
    "#Total row count for complete_2019_df should be: --------."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418fbbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#append all 12 months to one df:\n",
    "complete_2019_df = clean_df_2019_01.append([clean_df_2019_02,\n",
    "                                           clean_df_2019_03,\n",
    "                                           clean_df_2019_04,\n",
    "                                           clean_df_2019_05,\n",
    "                                           clean_df_2019_06,\n",
    "                                           clean_df_2019_07, \n",
    "                                           clean_df_2019_08,\n",
    "                                           clean_df_2019_09,\n",
    "                                           clean_df_2019_10, \n",
    "                                           clean_df_2019_11, \n",
    "                                           clean_df_2019_12], ignore_index = True)\n",
    "complete_2019_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3599b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verify the total row count is accurate. \n",
    "complete_2019_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47f5606",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_2019_df.reset_index(inplace=True)\n",
    "complete_2019_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4485cf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Order Number column so that SQL has a unique value to assign as the Primary Key.\n",
    "complete_2019_df.rename(columns={'index': 'Order Number'}, inplace=True)\n",
    "complete_2019_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175dcd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export complete_2019_df to .csv\n",
    "complete_2019_df.to_csv('Complete_annual_dataframes/Complete_2019.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd797607",
   "metadata": {},
   "source": [
    "## Connect Pandas to SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46707378",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a database and create tables in pgAdmin (PostgreSQL). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e70f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the complete_2021 csv\n",
    "load_2019 = \"Complete_annual_dataframes/Complete_2019.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e58f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Complete_states.csv into a DataFrame\n",
    "Complete_2019 = pd.read_csv(load_2019)\n",
    "Complete_2019.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df2f8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the database engine that will allow Pandas to communicate with our SQL server.\n",
    "#\"postgresql://[user]:[password]@[location]:[port]/[database]\"\n",
    "#For our local server, the connection string will be as follows:\n",
    "db_string = f\"postgresql://postgres:{db_password}@127.0.0.1:5432/Winedemic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb3c121",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the database engine\n",
    "engine = create_engine(db_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acc60c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the df to a SQL table.\n",
    "#complete_2019_df.to_sql(name='complete_2019', con=engine)\n",
    "#This is for a smaller data set. Probably need to use the code below to connect the large .csv\n",
    "#Probably can use this code for the states df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc82b0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To import large data:\n",
    "# Do not run this yet! This can take upwwards of an hour.\n",
    "# create a variable for the number of rows imported\n",
    "rows_imported = 0\n",
    "# get the start_time from time.time()\n",
    "start_time = time.time()\n",
    "for complete_2019 in pd.read_csv(f'{load_2019}', chunksize=100000): \n",
    "\n",
    "    # print out the range of rows that are being imported\n",
    "    print(f'importing rows {rows_imported} to {rows_imported + len(complete_2019)}...', end='')\n",
    "\n",
    "    complete_2019.to_sql(name='complete_2019', con=engine, if_exists='append')\n",
    "\n",
    "    # increment the number of rows imported by the size of 'data'\n",
    "    rows_imported += len(complete_2019)\n",
    "\n",
    "    # add elapsed time to final print out\n",
    "    print(f'Done. {time.time() - start_time} total seconds elapsed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686f27fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In pgAdmin, confirm that the table imported correctly. Follow these steps:\n",
    "#Right-click the \"complete_2019\" table name and select Properties.\n",
    "#Click the Columns tab to make sure all columns have an appropriate data type.\n",
    "#Close the Properties window, and then right-click \"complete_2019\" again.\n",
    "#Select \"View/Edit Data\" followed by \"First 100 Rows.\"\n",
    "#Right-click \"complete_2019\" and select Query Tool.\n",
    "#Inside the Query Editor, run the query select count(*) from complete_2019 to make sure all the rows were imported."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
